# Toy MDP simulator

Visualise the optimal policies in a toy mdp described by you.

## Overview

MDPs provide a structured way to analyze decision-making under uncertainty, offering insights into optimal decision strategies and behavior in complex environments. Here you can define a toy mdp visually and get the optimal policies calculated.

## Features

- Schematic of the MDP
- View the transition probability model
- Get the optimal policy mappings from each state at your discount factor

## Screenshots

<div style="display: flex; flex-direction: row; justify-content: space-around;">
    <img src="https://github.com/harsh-choudhary-nature/mdp/blob/main/Screenshot_2024-07-31-21-45-29-076_com.example.mdp.jpg" alt="Screenshot 1" width="250" />
    <img src="https://github.com/harsh-choudhary-nature/mdp/blob/main/Screenshot_2024-07-31-21-45-49-959_com.example.mdp.jpg" alt="Screenshot 2" width="250" />
    <img src="https://github.com/harsh-choudhary-nature/mdp/blob/main/Screenshot_2024-07-31-21-46-08-263_com.example.mdp.jpg" alt="Screenshot 3" width="250" />
</div>

## Contributing

If you'd like to contribute to this project, please follow these steps.

1. Fork this repository.
2. Create a new branch (`git checkout -b feature-branch`).
3. Make your changes.
4. Commit your changes (`git commit -am 'Add new feature'`).
5. Push to the branch (`git push origin feature-branch`).
6. Create a new Pull Request.
