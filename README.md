# Toy MDP simulator

Visualise the optimal policies in a toy mdp described by you.

## Overview

MDPs provide a structured way to analyze decision-making under uncertainty, offering insights into optimal decision strategies and behavior in complex environments. Here you can define a toy mdp visually and get the optimal policies calculated.

## Features

- Schematic of the MDP
- View the transition probability model
- Get the optimal policy mappings from each state at your discount factor

## Screenshots

![Screenshot 1](https://github.com/harsh-choudhary-nature/mdp/blob/main/Screenshot_2024-07-31-21-45-29-076_com.example.mdp.jpg)
*Caption for Screenshot 1*

![Screenshot 2](https://github.com/harsh-choudhary-nature/mdp/blob/main/Screenshot_2024-07-31-21-45-49-959_com.example.mdp.jpg)
*Caption for Screenshot 2*

![Screenshot 3](https://github.com/harsh-choudhary-nature/mdp/blob/main/Screenshot_2024-07-31-21-46-08-263_com.example.mdp.jpg)
*Caption for Screenshot 3*

## Contributing

If you'd like to contribute to this project, please follow these steps.

1. Fork this repository.
2. Create a new branch (`git checkout -b feature-branch`).
3. Make your changes.
4. Commit your changes (`git commit -am 'Add new feature'`).
5. Push to the branch (`git push origin feature-branch`).
6. Create a new Pull Request.
